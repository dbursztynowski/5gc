# HELP go_gc_cycles_automatic_gc_cycles_total Count of completed GC cycles generated by the Go runtime.
# TYPE go_gc_cycles_automatic_gc_cycles_total counter
go_gc_cycles_automatic_gc_cycles_total 3585
# HELP go_gc_cycles_forced_gc_cycles_total Count of completed GC cycles forced by the application.
# TYPE go_gc_cycles_forced_gc_cycles_total counter
go_gc_cycles_forced_gc_cycles_total 0
# HELP go_gc_cycles_total_gc_cycles_total Count of all completed GC cycles.
# TYPE go_gc_cycles_total_gc_cycles_total counter
go_gc_cycles_total_gc_cycles_total 3585
# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 9.8508e-05
go_gc_duration_seconds{quantile="0.25"} 0.000142811
go_gc_duration_seconds{quantile="0.5"} 0.00018072
go_gc_duration_seconds{quantile="0.75"} 0.000325783
go_gc_duration_seconds{quantile="1"} 0.009352987
go_gc_duration_seconds_sum 1.184025327
go_gc_duration_seconds_count 3585
# HELP go_gc_gogc_percent Heap size target percentage configured by the user, otherwise 100. This value is set by the GOGC environment variable, and the runtime/debug.SetGCPercent function.
# TYPE go_gc_gogc_percent gauge
go_gc_gogc_percent 75
# HELP go_gc_gomemlimit_bytes Go runtime memory limit configured by the user, otherwise math.MaxInt64. This value is set by the GOMEMLIMIT environment variable, and the runtime/debug.SetMemoryLimit function.
# TYPE go_gc_gomemlimit_bytes gauge
go_gc_gomemlimit_bytes 9.223372036854776e+18
# HELP go_gc_heap_allocs_by_size_bytes Distribution of heap allocations by approximate size. Bucket counts increase monotonically. Note that this does not include tiny objects as defined by /gc/heap/tiny/allocs:objects, only tiny blocks.
# TYPE go_gc_heap_allocs_by_size_bytes histogram
go_gc_heap_allocs_by_size_bytes_bucket{le="8.999999999999998"} 4.0882831e+07
go_gc_heap_allocs_by_size_bytes_bucket{le="24.999999999999996"} 1.740706084e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="64.99999999999999"} 3.380708845e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="144.99999999999997"} 5.202282072e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="320.99999999999994"} 5.512470293e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="704.9999999999999"} 5.564559529e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="1536.9999999999998"} 5.585104123e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="3200.9999999999995"} 5.590787627e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="6528.999999999999"} 5.594035667e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="13568.999999999998"} 5.596309848e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="27264.999999999996"} 5.597129445e+09
go_gc_heap_allocs_by_size_bytes_bucket{le="+Inf"} 5.598158656e+09
go_gc_heap_allocs_by_size_bytes_sum 5.8610740712e+11
go_gc_heap_allocs_by_size_bytes_count 5.598158656e+09
# HELP go_gc_heap_allocs_bytes_total Cumulative sum of memory allocated to the heap by the application.
# TYPE go_gc_heap_allocs_bytes_total counter
go_gc_heap_allocs_bytes_total 5.8610740712e+11
# HELP go_gc_heap_allocs_objects_total Cumulative count of heap allocations triggered by the application. Note that this does not include tiny objects as defined by /gc/heap/tiny/allocs:objects, only tiny blocks.
# TYPE go_gc_heap_allocs_objects_total counter
go_gc_heap_allocs_objects_total 5.598158656e+09
# HELP go_gc_heap_frees_by_size_bytes Distribution of freed heap allocations by approximate size. Bucket counts increase monotonically. Note that this does not include tiny objects as defined by /gc/heap/tiny/allocs:objects, only tiny blocks.
# TYPE go_gc_heap_frees_by_size_bytes histogram
go_gc_heap_frees_by_size_bytes_bucket{le="8.999999999999998"} 4.0874097e+07
go_gc_heap_frees_by_size_bytes_bucket{le="24.999999999999996"} 1.740187118e+09
go_gc_heap_frees_by_size_bytes_bucket{le="64.99999999999999"} 3.378904188e+09
go_gc_heap_frees_by_size_bytes_bucket{le="144.99999999999997"} 5.199853517e+09
go_gc_heap_frees_by_size_bytes_bucket{le="320.99999999999994"} 5.509699792e+09
go_gc_heap_frees_by_size_bytes_bucket{le="704.9999999999999"} 5.561760269e+09
go_gc_heap_frees_by_size_bytes_bucket{le="1536.9999999999998"} 5.582297425e+09
go_gc_heap_frees_by_size_bytes_bucket{le="3200.9999999999995"} 5.587979082e+09
go_gc_heap_frees_by_size_bytes_bucket{le="6528.999999999999"} 5.591224967e+09
go_gc_heap_frees_by_size_bytes_bucket{le="13568.999999999998"} 5.593498265e+09
go_gc_heap_frees_by_size_bytes_bucket{le="27264.999999999996"} 5.594317453e+09
go_gc_heap_frees_by_size_bytes_bucket{le="+Inf"} 5.595346234e+09
go_gc_heap_frees_by_size_bytes_sum 5.85746756576e+11
go_gc_heap_frees_by_size_bytes_count 5.595346234e+09
# HELP go_gc_heap_frees_bytes_total Cumulative sum of heap memory freed by the garbage collector.
# TYPE go_gc_heap_frees_bytes_total counter
go_gc_heap_frees_bytes_total 5.85746756576e+11
# HELP go_gc_heap_frees_objects_total Cumulative count of heap allocations whose storage was freed by the garbage collector. Note that this does not include tiny objects as defined by /gc/heap/tiny/allocs:objects, only tiny blocks.
# TYPE go_gc_heap_frees_objects_total counter
go_gc_heap_frees_objects_total 5.595346234e+09
# HELP go_gc_heap_goal_bytes Heap size target for the end of the GC cycle.
# TYPE go_gc_heap_goal_bytes gauge
go_gc_heap_goal_bytes 4.42553482e+08
# HELP go_gc_heap_live_bytes Heap memory occupied by live objects that were marked by the previous GC.
# TYPE go_gc_heap_live_bytes gauge
go_gc_heap_live_bytes 2.52386296e+08
# HELP go_gc_heap_objects_objects Number of objects, live or unswept, occupying heap memory.
# TYPE go_gc_heap_objects_objects gauge
go_gc_heap_objects_objects 2.812422e+06
# HELP go_gc_heap_tiny_allocs_objects_total Count of small allocations that are packed together into blocks. These allocations are counted separately from other allocations because each individual allocation is not tracked by the runtime, only their block. Each block is already accounted for in allocs-by-size and frees-by-size.
# TYPE go_gc_heap_tiny_allocs_objects_total counter
go_gc_heap_tiny_allocs_objects_total 6.74481112e+08
# HELP go_gc_limiter_last_enabled_gc_cycle GC cycle the last time the GC CPU limiter was enabled. This metric is useful for diagnosing the root cause of an out-of-memory error, because the limiter trades memory for CPU time when the GC's CPU time gets too high. This is most likely to occur with use of SetMemoryLimit. The first GC cycle is cycle 1, so a value of 0 indicates that it was never enabled.
# TYPE go_gc_limiter_last_enabled_gc_cycle gauge
go_gc_limiter_last_enabled_gc_cycle 0
# HELP go_gc_pauses_seconds Deprecated. Prefer the identical /sched/pauses/total/gc:seconds.
# TYPE go_gc_pauses_seconds histogram
go_gc_pauses_seconds_bucket{le="6.399999999999999e-08"} 0
go_gc_pauses_seconds_bucket{le="6.399999999999999e-07"} 0
go_gc_pauses_seconds_bucket{le="7.167999999999999e-06"} 1546
go_gc_pauses_seconds_bucket{le="8.191999999999999e-05"} 3417
go_gc_pauses_seconds_bucket{le="0.0009175039999999999"} 7039
go_gc_pauses_seconds_bucket{le="0.010485759999999998"} 7168
go_gc_pauses_seconds_bucket{le="0.11744051199999998"} 7170
go_gc_pauses_seconds_bucket{le="+Inf"} 7170
go_gc_pauses_seconds_sum 0.45044454400000006
go_gc_pauses_seconds_count 7170
# HELP go_gc_scan_globals_bytes The total amount of global variable space that is scannable.
# TYPE go_gc_scan_globals_bytes gauge
go_gc_scan_globals_bytes 828640
# HELP go_gc_scan_heap_bytes The total amount of heap space that is scannable.
# TYPE go_gc_scan_heap_bytes gauge
go_gc_scan_heap_bytes 1.28080424e+08
# HELP go_gc_scan_stack_bytes The number of bytes of stack that were scanned last GC cycle.
# TYPE go_gc_scan_stack_bytes gauge
go_gc_scan_stack_bytes 341312
# HELP go_gc_scan_total_bytes The total amount space that is scannable. Sum of all metrics in /gc/scan.
# TYPE go_gc_scan_total_bytes gauge
go_gc_scan_total_bytes 1.29250376e+08
# HELP go_gc_stack_starting_size_bytes The stack size of new goroutines.
# TYPE go_gc_stack_starting_size_bytes gauge
go_gc_stack_starting_size_bytes 4096
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 285
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
go_info{version="go1.22.6"} 1
# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.
# TYPE go_memstats_alloc_bytes gauge
go_memstats_alloc_bytes 3.60650544e+08
# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.
# TYPE go_memstats_alloc_bytes_total counter
go_memstats_alloc_bytes_total 5.8610740712e+11
# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.
# TYPE go_memstats_buck_hash_sys_bytes gauge
go_memstats_buck_hash_sys_bytes 8.511527e+06
# HELP go_memstats_frees_total Total number of frees.
# TYPE go_memstats_frees_total counter
go_memstats_frees_total 6.269827346e+09
# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.
# TYPE go_memstats_gc_sys_bytes gauge
go_memstats_gc_sys_bytes 8.195832e+06
# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.
# TYPE go_memstats_heap_alloc_bytes gauge
go_memstats_heap_alloc_bytes 3.60650544e+08
# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.
# TYPE go_memstats_heap_idle_bytes gauge
go_memstats_heap_idle_bytes 1.86523648e+08
# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.
# TYPE go_memstats_heap_inuse_bytes gauge
go_memstats_heap_inuse_bytes 3.93617408e+08
# HELP go_memstats_heap_objects Number of allocated objects.
# TYPE go_memstats_heap_objects gauge
go_memstats_heap_objects 2.812422e+06
# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.
# TYPE go_memstats_heap_released_bytes gauge
go_memstats_heap_released_bytes 1.10608384e+08
# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.
# TYPE go_memstats_heap_sys_bytes gauge
go_memstats_heap_sys_bytes 5.80141056e+08
# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.
# TYPE go_memstats_last_gc_time_seconds gauge
go_memstats_last_gc_time_seconds 1.7285822044947836e+09
# HELP go_memstats_lookups_total Total number of pointer lookups.
# TYPE go_memstats_lookups_total counter
go_memstats_lookups_total 0
# HELP go_memstats_mallocs_total Total number of mallocs.
# TYPE go_memstats_mallocs_total counter
go_memstats_mallocs_total 6.272639768e+09
# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.
# TYPE go_memstats_mcache_inuse_bytes gauge
go_memstats_mcache_inuse_bytes 4800
# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.
# TYPE go_memstats_mcache_sys_bytes gauge
go_memstats_mcache_sys_bytes 15600
# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.
# TYPE go_memstats_mspan_inuse_bytes gauge
go_memstats_mspan_inuse_bytes 5.288e+06
# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.
# TYPE go_memstats_mspan_sys_bytes gauge
go_memstats_mspan_sys_bytes 6.54432e+06
# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.
# TYPE go_memstats_next_gc_bytes gauge
go_memstats_next_gc_bytes 4.42553482e+08
# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.
# TYPE go_memstats_other_sys_bytes gauge
go_memstats_other_sys_bytes 1.310137e+06
# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.
# TYPE go_memstats_stack_inuse_bytes gauge
go_memstats_stack_inuse_bytes 6.979584e+06
# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.
# TYPE go_memstats_stack_sys_bytes gauge
go_memstats_stack_sys_bytes 6.979584e+06
# HELP go_memstats_sys_bytes Number of bytes obtained from system.
# TYPE go_memstats_sys_bytes gauge
go_memstats_sys_bytes 6.11698056e+08
# HELP go_sched_gomaxprocs_threads The current runtime.GOMAXPROCS setting, or the number of operating system threads that can execute user-level Go code simultaneously.
# TYPE go_sched_gomaxprocs_threads gauge
go_sched_gomaxprocs_threads 4
# HELP go_sched_goroutines_goroutines Count of live goroutines.
# TYPE go_sched_goroutines_goroutines gauge
go_sched_goroutines_goroutines 285
# HELP go_sched_latencies_seconds Distribution of the time goroutines have spent in the scheduler in a runnable state before actually running. Bucket counts increase monotonically.
# TYPE go_sched_latencies_seconds histogram
go_sched_latencies_seconds_bucket{le="6.399999999999999e-08"} 2.110964e+06
go_sched_latencies_seconds_bucket{le="6.399999999999999e-07"} 2.366166e+06
go_sched_latencies_seconds_bucket{le="7.167999999999999e-06"} 2.693768e+06
go_sched_latencies_seconds_bucket{le="8.191999999999999e-05"} 3.39116e+06
go_sched_latencies_seconds_bucket{le="0.0009175039999999999"} 3.472446e+06
go_sched_latencies_seconds_bucket{le="0.010485759999999998"} 3.479624e+06
go_sched_latencies_seconds_bucket{le="0.11744051199999998"} 3.479669e+06
go_sched_latencies_seconds_bucket{le="+Inf"} 3.479669e+06
go_sched_latencies_seconds_sum 18.941556096
go_sched_latencies_seconds_count 3.479669e+06
# HELP go_sched_pauses_stopping_gc_seconds Distribution of individual GC-related stop-the-world stopping latencies. This is the time it takes from deciding to stop the world until all Ps are stopped. This is a subset of the total GC-related stop-the-world time (/sched/pauses/total/gc:seconds). During this time, some threads may be executing. Bucket counts increase monotonically.
# TYPE go_sched_pauses_stopping_gc_seconds histogram
go_sched_pauses_stopping_gc_seconds_bucket{le="6.399999999999999e-08"} 0
go_sched_pauses_stopping_gc_seconds_bucket{le="6.399999999999999e-07"} 456
go_sched_pauses_stopping_gc_seconds_bucket{le="7.167999999999999e-06"} 4818
go_sched_pauses_stopping_gc_seconds_bucket{le="8.191999999999999e-05"} 6803
go_sched_pauses_stopping_gc_seconds_bucket{le="0.0009175039999999999"} 7115
go_sched_pauses_stopping_gc_seconds_bucket{le="0.010485759999999998"} 7169
go_sched_pauses_stopping_gc_seconds_bucket{le="0.11744051199999998"} 7170
go_sched_pauses_stopping_gc_seconds_bucket{le="+Inf"} 7170
go_sched_pauses_stopping_gc_seconds_sum 0.10263936
go_sched_pauses_stopping_gc_seconds_count 7170
# HELP go_sched_pauses_stopping_other_seconds Distribution of individual non-GC-related stop-the-world stopping latencies. This is the time it takes from deciding to stop the world until all Ps are stopped. This is a subset of the total non-GC-related stop-the-world time (/sched/pauses/total/other:seconds). During this time, some threads may be executing. Bucket counts increase monotonically.
# TYPE go_sched_pauses_stopping_other_seconds histogram
go_sched_pauses_stopping_other_seconds_bucket{le="6.399999999999999e-08"} 0
go_sched_pauses_stopping_other_seconds_bucket{le="6.399999999999999e-07"} 0
go_sched_pauses_stopping_other_seconds_bucket{le="7.167999999999999e-06"} 0
go_sched_pauses_stopping_other_seconds_bucket{le="8.191999999999999e-05"} 0
go_sched_pauses_stopping_other_seconds_bucket{le="0.0009175039999999999"} 0
go_sched_pauses_stopping_other_seconds_bucket{le="0.010485759999999998"} 0
go_sched_pauses_stopping_other_seconds_bucket{le="0.11744051199999998"} 0
go_sched_pauses_stopping_other_seconds_bucket{le="+Inf"} 0
go_sched_pauses_stopping_other_seconds_sum 0
go_sched_pauses_stopping_other_seconds_count 0
# HELP go_sched_pauses_total_gc_seconds Distribution of individual GC-related stop-the-world pause latencies. This is the time from deciding to stop the world until the world is started again. Some of this time is spent getting all threads to stop (this is measured directly in /sched/pauses/stopping/gc:seconds), during which some threads may still be running. Bucket counts increase monotonically.
# TYPE go_sched_pauses_total_gc_seconds histogram
go_sched_pauses_total_gc_seconds_bucket{le="6.399999999999999e-08"} 0
go_sched_pauses_total_gc_seconds_bucket{le="6.399999999999999e-07"} 0
go_sched_pauses_total_gc_seconds_bucket{le="7.167999999999999e-06"} 1546
go_sched_pauses_total_gc_seconds_bucket{le="8.191999999999999e-05"} 3417
go_sched_pauses_total_gc_seconds_bucket{le="0.0009175039999999999"} 7039
go_sched_pauses_total_gc_seconds_bucket{le="0.010485759999999998"} 7168
go_sched_pauses_total_gc_seconds_bucket{le="0.11744051199999998"} 7170
go_sched_pauses_total_gc_seconds_bucket{le="+Inf"} 7170
go_sched_pauses_total_gc_seconds_sum 0.45044454400000006
go_sched_pauses_total_gc_seconds_count 7170
# HELP go_sched_pauses_total_other_seconds Distribution of individual non-GC-related stop-the-world pause latencies. This is the time from deciding to stop the world until the world is started again. Some of this time is spent getting all threads to stop (measured directly in /sched/pauses/stopping/other:seconds). Bucket counts increase monotonically.
# TYPE go_sched_pauses_total_other_seconds histogram
go_sched_pauses_total_other_seconds_bucket{le="6.399999999999999e-08"} 0
go_sched_pauses_total_other_seconds_bucket{le="6.399999999999999e-07"} 0
go_sched_pauses_total_other_seconds_bucket{le="7.167999999999999e-06"} 0
go_sched_pauses_total_other_seconds_bucket{le="8.191999999999999e-05"} 0
go_sched_pauses_total_other_seconds_bucket{le="0.0009175039999999999"} 0
go_sched_pauses_total_other_seconds_bucket{le="0.010485759999999998"} 0
go_sched_pauses_total_other_seconds_bucket{le="0.11744051199999998"} 0
go_sched_pauses_total_other_seconds_bucket{le="+Inf"} 0
go_sched_pauses_total_other_seconds_sum 0
go_sched_pauses_total_other_seconds_count 0
# HELP go_threads Number of OS threads created.
# TYPE go_threads gauge
go_threads 11
# HELP net_conntrack_dialer_conn_attempted_total Total number of connections attempted by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_attempted_total counter
net_conntrack_dialer_conn_attempted_total{dialer_name="alertmanager"} 12
net_conntrack_dialer_conn_attempted_total{dialer_name="default"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/default/open5gs-amf/0"} 502
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/default/open5gs-pcf/0"} 501
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/default/open5gs-smf/0"} 501
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/default/open5gs-upf/0"} 502
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/0"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/1"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/blackbox-exporter/0"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/coredns/0"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/grafana/0"} 3
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/0"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/1"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/0"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/1"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/0"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/1"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/0"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/1"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kubelet/0"} 2
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kubelet/1"} 2
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kubelet/2"} 2
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/kubelet/3"} 2
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/node-exporter/0"} 7
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/prometheus-adapter/0"} 2
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/0"} 2
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/1"} 2
net_conntrack_dialer_conn_attempted_total{dialer_name="serviceMonitor/monitoring/prometheus-operator/0"} 2
# HELP net_conntrack_dialer_conn_closed_total Total number of connections closed which originated from the dialer of a given name.
# TYPE net_conntrack_dialer_conn_closed_total counter
net_conntrack_dialer_conn_closed_total{dialer_name="alertmanager"} 9
net_conntrack_dialer_conn_closed_total{dialer_name="default"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/default/open5gs-amf/0"} 502
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/default/open5gs-pcf/0"} 493
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/default/open5gs-smf/0"} 501
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/default/open5gs-upf/0"} 502
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/blackbox-exporter/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/coredns/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/grafana/0"} 1
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kubelet/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kubelet/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kubelet/2"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/kubelet/3"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/node-exporter/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/prometheus-adapter/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/0"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/1"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="serviceMonitor/monitoring/prometheus-operator/0"} 0
# HELP net_conntrack_dialer_conn_established_total Total number of connections successfully established by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_established_total counter
net_conntrack_dialer_conn_established_total{dialer_name="alertmanager"} 12
net_conntrack_dialer_conn_established_total{dialer_name="default"} 0
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/default/open5gs-amf/0"} 502
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/default/open5gs-pcf/0"} 493
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/default/open5gs-smf/0"} 501
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/default/open5gs-upf/0"} 502
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/0"} 3
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/1"} 3
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/blackbox-exporter/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/coredns/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/grafana/0"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/1"} 1
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/0"} 0
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/1"} 0
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/0"} 0
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/1"} 0
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/0"} 1
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/1"} 1
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kubelet/0"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kubelet/1"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kubelet/2"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/kubelet/3"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/node-exporter/0"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/prometheus-adapter/0"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/0"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/1"} 2
net_conntrack_dialer_conn_established_total{dialer_name="serviceMonitor/monitoring/prometheus-operator/0"} 1
# HELP net_conntrack_dialer_conn_failed_total Total number of connections failed to dial by the dialer a given name.
# TYPE net_conntrack_dialer_conn_failed_total counter
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="alertmanager",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-amf/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-amf/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-amf/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-amf/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-pcf/0",reason="refused"} 8
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-pcf/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-pcf/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-pcf/0",reason="unknown"} 8
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-smf/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-smf/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-smf/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-smf/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-upf/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-upf/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-upf/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/default/open5gs-upf/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/alertmanager-main/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/blackbox-exporter/0",reason="refused"} 2
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/blackbox-exporter/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/blackbox-exporter/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/blackbox-exporter/0",reason="unknown"} 2
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/coredns/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/coredns/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/coredns/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/coredns/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/grafana/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/grafana/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/grafana/0",reason="timeout"} 1
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/grafana/0",reason="unknown"} 1
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-apiserver/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-controller-manager/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-scheduler/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kube-state-metrics/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/2",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/2",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/2",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/2",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/3",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/3",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/3",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/kubelet/3",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/node-exporter/0",reason="refused"} 5
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/node-exporter/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/node-exporter/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/node-exporter/0",reason="unknown"} 5
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-adapter/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-adapter/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-adapter/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-adapter/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/0",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/0",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/1",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/1",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/1",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-k8s/1",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-operator/0",reason="refused"} 1
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-operator/0",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-operator/0",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="serviceMonitor/monitoring/prometheus-operator/0",reason="unknown"} 1
# HELP net_conntrack_listener_conn_accepted_total Total number of connections opened to the listener of a given name.
# TYPE net_conntrack_listener_conn_accepted_total counter
net_conntrack_listener_conn_accepted_total{listener_name="http"} 99579
# HELP net_conntrack_listener_conn_closed_total Total number of connections closed that were made to the listener of a given name.
# TYPE net_conntrack_listener_conn_closed_total counter
net_conntrack_listener_conn_closed_total{listener_name="http"} 99576
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 12873.54
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1.048576e+06
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 76
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 6.47651328e+08
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.72833350903e+09
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 2.644897792e+09
# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.
# TYPE process_virtual_memory_max_bytes gauge
process_virtual_memory_max_bytes 1.8446744073709552e+19
# HELP prometheus_api_remote_read_queries The current number of remote read queries being executed or waiting.
# TYPE prometheus_api_remote_read_queries gauge
prometheus_api_remote_read_queries 0
# HELP prometheus_build_info A metric with a constant '1' value labeled by version, revision, branch, goversion from which prometheus was built, and the goos and goarch for the build.
# TYPE prometheus_build_info gauge
prometheus_build_info{branch="HEAD",goarch="amd64",goos="linux",goversion="go1.22.6",revision="e6cfa720fbe6280153fab13090a483dbd40bece3",tags="netgo,builtinassets,stringlabels",version="2.54.1"} 1
# HELP prometheus_config_last_reload_success_timestamp_seconds Timestamp of the last successful configuration reload.
# TYPE prometheus_config_last_reload_success_timestamp_seconds gauge
prometheus_config_last_reload_success_timestamp_seconds 1.7285674588338513e+09
# HELP prometheus_config_last_reload_successful Whether the last configuration reload attempt was successful.
# TYPE prometheus_config_last_reload_successful gauge
prometheus_config_last_reload_successful 1
# HELP prometheus_engine_queries The current number of queries being executed or waiting.
# TYPE prometheus_engine_queries gauge
prometheus_engine_queries 0
# HELP prometheus_engine_queries_concurrent_max The max number of concurrent queries.
# TYPE prometheus_engine_queries_concurrent_max gauge
prometheus_engine_queries_concurrent_max 20
# HELP prometheus_engine_query_duration_seconds Query timings
# TYPE prometheus_engine_query_duration_seconds summary
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.5"} 0.000199727
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.9"} 0.002999755
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.99"} 0.144517236
prometheus_engine_query_duration_seconds_sum{slice="inner_eval"} 5931.890994281879
prometheus_engine_query_duration_seconds_count{slice="inner_eval"} 1.682058e+06
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.5"} 3.1597e-05
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.9"} 9.9195e-05
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.99"} 0.003009657
prometheus_engine_query_duration_seconds_sum{slice="prepare_time"} 188.97592711801235
prometheus_engine_query_duration_seconds_count{slice="prepare_time"} 1.682058e+06
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.5"} 7.155e-06
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.9"} 1.6337e-05
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.99"} 4.7914e-05
prometheus_engine_query_duration_seconds_sum{slice="queue_time"} 31.286705446000624
prometheus_engine_query_duration_seconds_count{slice="queue_time"} 3.364132e+06
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.5"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.9"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.99"} NaN
prometheus_engine_query_duration_seconds_sum{slice="result_sort"} 0.001823731000000001
prometheus_engine_query_duration_seconds_count{slice="result_sort"} 902
# HELP prometheus_engine_query_log_enabled State of the query log.
# TYPE prometheus_engine_query_log_enabled gauge
prometheus_engine_query_log_enabled 0
# HELP prometheus_engine_query_log_failures_total The number of query log failures.
# TYPE prometheus_engine_query_log_failures_total counter
prometheus_engine_query_log_failures_total 0
# HELP prometheus_engine_query_samples_total The total number of samples loaded by all queries.
# TYPE prometheus_engine_query_samples_total counter
prometheus_engine_query_samples_total 3.9156110221e+10
# HELP prometheus_http_request_duration_seconds Histogram of latencies for HTTP requests.
# TYPE prometheus_http_request_duration_seconds histogram
prometheus_http_request_duration_seconds_bucket{handler="/",le="0.1"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="0.2"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="0.4"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="1"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="3"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="8"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="20"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="60"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="120"} 3
prometheus_http_request_duration_seconds_bucket{handler="/",le="+Inf"} 3
prometheus_http_request_duration_seconds_sum{handler="/"} 0.000176393
prometheus_http_request_duration_seconds_count{handler="/"} 3
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.1"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.2"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.4"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="1"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="3"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="8"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="20"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="60"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="120"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="+Inf"} 49745
prometheus_http_request_duration_seconds_sum{handler="/-/healthy"} 1.0004982749999978
prometheus_http_request_duration_seconds_count{handler="/-/healthy"} 49745
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.1"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.2"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.4"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="1"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="3"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="8"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="20"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="60"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="120"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="+Inf"} 49747
prometheus_http_request_duration_seconds_sum{handler="/-/ready"} 1.0455671840000047
prometheus_http_request_duration_seconds_count{handler="/-/ready"} 49747
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="0.1"} 3
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="0.2"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="0.4"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="1"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="3"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="8"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="20"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="60"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="120"} 4
prometheus_http_request_duration_seconds_bucket{handler="/-/reload",le="+Inf"} 4
prometheus_http_request_duration_seconds_sum{handler="/-/reload"} 0.36720178200000003
prometheus_http_request_duration_seconds_count{handler="/-/reload"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="0.1"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="0.2"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="0.4"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="1"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="3"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="8"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="20"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="60"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="120"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/label/:name/values",le="+Inf"} 372
prometheus_http_request_duration_seconds_sum{handler="/api/v1/label/:name/values"} 1.2503285439999998
prometheus_http_request_duration_seconds_count{handler="/api/v1/label/:name/values"} 372
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="0.1"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="0.2"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="0.4"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="1"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="3"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="8"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="20"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="60"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="120"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/labels",le="+Inf"} 11
prometheus_http_request_duration_seconds_sum{handler="/api/v1/labels"} 0.009645982
prometheus_http_request_duration_seconds_count{handler="/api/v1/labels"} 11
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="0.1"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="0.2"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="0.4"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="1"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="3"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="8"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="20"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="60"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="120"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/metadata",le="+Inf"} 3
prometheus_http_request_duration_seconds_sum{handler="/api/v1/metadata"} 0.043731721
prometheus_http_request_duration_seconds_count{handler="/api/v1/metadata"} 3
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="0.1"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="0.2"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="0.4"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="1"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="3"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="8"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="20"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="60"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="120"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query",le="+Inf"} 852
prometheus_http_request_duration_seconds_sum{handler="/api/v1/query"} 1.1533343740000002
prometheus_http_request_duration_seconds_count{handler="/api/v1/query"} 852
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="0.1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="0.2"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="0.4"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="3"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="8"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="20"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="60"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="120"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_exemplars",le="+Inf"} 2
prometheus_http_request_duration_seconds_sum{handler="/api/v1/query_exemplars"} 0.001768478
prometheus_http_request_duration_seconds_count{handler="/api/v1/query_exemplars"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="0.1"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="0.2"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="0.4"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="1"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="3"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="8"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="20"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="60"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="120"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query_range",le="+Inf"} 902
prometheus_http_request_duration_seconds_sum{handler="/api/v1/query_range"} 1.6286578240000018
prometheus_http_request_duration_seconds_count{handler="/api/v1/query_range"} 902
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="0.1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="0.2"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="0.4"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="1"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="3"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="8"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="20"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="60"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="120"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/rules",le="+Inf"} 2
prometheus_http_request_duration_seconds_sum{handler="/api/v1/rules"} 0.018834382
prometheus_http_request_duration_seconds_count{handler="/api/v1/rules"} 2
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="0.1"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="0.2"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="0.4"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="1"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="3"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="8"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="20"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="60"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="120"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/series",le="+Inf"} 1
prometheus_http_request_duration_seconds_sum{handler="/api/v1/series"} 0.002038236
prometheus_http_request_duration_seconds_count{handler="/api/v1/series"} 1
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="0.1"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="0.2"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="0.4"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="1"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="3"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="8"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="20"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="60"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="120"} 4
prometheus_http_request_duration_seconds_bucket{handler="/api/v1/status/buildinfo",le="+Inf"} 4
prometheus_http_request_duration_seconds_sum{handler="/api/v1/status/buildinfo"} 0.003287761
prometheus_http_request_duration_seconds_count{handler="/api/v1/status/buildinfo"} 4
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.1"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.2"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.4"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="1"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="3"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="8"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="20"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="60"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="120"} 33166
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="+Inf"} 33166
prometheus_http_request_duration_seconds_sum{handler="/metrics"} 497.392120722002
prometheus_http_request_duration_seconds_count{handler="/metrics"} 33166
# HELP prometheus_http_requests_total Counter of HTTP requests.
# TYPE prometheus_http_requests_total counter
prometheus_http_requests_total{code="200",handler="/"} 0
prometheus_http_requests_total{code="200",handler="/-/healthy"} 49745
prometheus_http_requests_total{code="200",handler="/-/quit"} 0
prometheus_http_requests_total{code="200",handler="/-/ready"} 49747
prometheus_http_requests_total{code="200",handler="/-/reload"} 4
prometheus_http_requests_total{code="200",handler="/alerts"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/*path"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/admin/tsdb/clean_tombstones"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/admin/tsdb/delete_series"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/admin/tsdb/snapshot"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/alertmanagers"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/alerts"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/format_query"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/label/:name/values"} 372
prometheus_http_requests_total{code="200",handler="/api/v1/labels"} 11
prometheus_http_requests_total{code="200",handler="/api/v1/metadata"} 3
prometheus_http_requests_total{code="200",handler="/api/v1/otlp/v1/metrics"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/query"} 837
prometheus_http_requests_total{code="200",handler="/api/v1/query_exemplars"} 2
prometheus_http_requests_total{code="200",handler="/api/v1/query_range"} 902
prometheus_http_requests_total{code="200",handler="/api/v1/read"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/rules"} 2
prometheus_http_requests_total{code="200",handler="/api/v1/scrape_pools"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/series"} 1
prometheus_http_requests_total{code="200",handler="/api/v1/status/buildinfo"} 4
prometheus_http_requests_total{code="200",handler="/api/v1/status/config"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/status/flags"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/status/runtimeinfo"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/status/tsdb"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/status/walreplay"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/targets"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/targets/metadata"} 0
prometheus_http_requests_total{code="200",handler="/api/v1/write"} 0
prometheus_http_requests_total{code="200",handler="/classic/static/*filepath"} 0
prometheus_http_requests_total{code="200",handler="/config"} 0
prometheus_http_requests_total{code="200",handler="/consoles/*filepath"} 0
prometheus_http_requests_total{code="200",handler="/debug/*subpath"} 0
prometheus_http_requests_total{code="200",handler="/favicon.ico"} 0
prometheus_http_requests_total{code="200",handler="/federate"} 0
prometheus_http_requests_total{code="200",handler="/flags"} 0
prometheus_http_requests_total{code="200",handler="/graph"} 0
prometheus_http_requests_total{code="200",handler="/manifest.json"} 0
prometheus_http_requests_total{code="200",handler="/metrics"} 33166
prometheus_http_requests_total{code="200",handler="/rules"} 0
prometheus_http_requests_total{code="200",handler="/service-discovery"} 0
prometheus_http_requests_total{code="200",handler="/starting"} 0
prometheus_http_requests_total{code="200",handler="/static/*filepath"} 0
prometheus_http_requests_total{code="200",handler="/status"} 0
prometheus_http_requests_total{code="200",handler="/targets"} 0
prometheus_http_requests_total{code="200",handler="/tsdb-status"} 0
prometheus_http_requests_total{code="200",handler="/version"} 0
prometheus_http_requests_total{code="302",handler="/"} 3
prometheus_http_requests_total{code="400",handler="/api/v1/query"} 14
prometheus_http_requests_total{code="499",handler="/api/v1/query"} 1
# HELP prometheus_http_response_size_bytes Histogram of response size for HTTP requests.
# TYPE prometheus_http_response_size_bytes histogram
prometheus_http_response_size_bytes_bucket{handler="/",le="100"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="1000"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="10000"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="100000"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+06"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+07"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+08"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="1e+09"} 3
prometheus_http_response_size_bytes_bucket{handler="/",le="+Inf"} 3
prometheus_http_response_size_bytes_sum{handler="/"} 87
prometheus_http_response_size_bytes_count{handler="/"} 3
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="100"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1000"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="10000"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="100000"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+06"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+07"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+08"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+09"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="+Inf"} 49745
prometheus_http_response_size_bytes_sum{handler="/-/healthy"} 1.49235e+06
prometheus_http_response_size_bytes_count{handler="/-/healthy"} 49745
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="100"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1000"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="10000"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="100000"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+06"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+07"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+08"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+09"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="+Inf"} 49747
prometheus_http_response_size_bytes_sum{handler="/-/ready"} 1.392916e+06
prometheus_http_response_size_bytes_count{handler="/-/ready"} 49747
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="100"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1000"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="10000"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="100000"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+06"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+07"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+08"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="1e+09"} 4
prometheus_http_response_size_bytes_bucket{handler="/-/reload",le="+Inf"} 4
prometheus_http_response_size_bytes_sum{handler="/-/reload"} 0
prometheus_http_response_size_bytes_count{handler="/-/reload"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="100"} 173
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1000"} 361
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="10000"} 361
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="100000"} 372
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+06"} 372
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+07"} 372
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+08"} 372
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="1e+09"} 372
prometheus_http_response_size_bytes_bucket{handler="/api/v1/label/:name/values",le="+Inf"} 372
prometheus_http_response_size_bytes_sum{handler="/api/v1/label/:name/values"} 190093
prometheus_http_response_size_bytes_count{handler="/api/v1/label/:name/values"} 372
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="10000"} 11
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="100000"} 11
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="1e+06"} 11
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="1e+07"} 11
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="1e+08"} 11
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="1e+09"} 11
prometheus_http_response_size_bytes_bucket{handler="/api/v1/labels",le="+Inf"} 11
prometheus_http_response_size_bytes_sum{handler="/api/v1/labels"} 14850
prometheus_http_response_size_bytes_count{handler="/api/v1/labels"} 11
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="10000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="100000"} 3
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="1e+06"} 3
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="1e+07"} 3
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="1e+08"} 3
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="1e+09"} 3
prometheus_http_response_size_bytes_bucket{handler="/api/v1/metadata",le="+Inf"} 3
prometheus_http_response_size_bytes_sum{handler="/api/v1/metadata"} 106670
prometheus_http_response_size_bytes_count{handler="/api/v1/metadata"} 3
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="100"} 239
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1000"} 849
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="10000"} 852
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="100000"} 852
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+06"} 852
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+07"} 852
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+08"} 852
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="1e+09"} 852
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query",le="+Inf"} 852
prometheus_http_response_size_bytes_sum{handler="/api/v1/query"} 193460
prometheus_http_response_size_bytes_count{handler="/api/v1/query"} 852
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="100"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="1000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="10000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="100000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="1e+06"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="1e+07"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="1e+08"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="1e+09"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_exemplars",le="+Inf"} 2
prometheus_http_response_size_bytes_sum{handler="/api/v1/query_exemplars"} 120
prometheus_http_response_size_bytes_count{handler="/api/v1/query_exemplars"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="100"} 295
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="1000"} 707
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="10000"} 902
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="100000"} 902
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="1e+06"} 902
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="1e+07"} 902
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="1e+08"} 902
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="1e+09"} 902
prometheus_http_response_size_bytes_bucket{handler="/api/v1/query_range",le="+Inf"} 902
prometheus_http_response_size_bytes_sum{handler="/api/v1/query_range"} 763297
prometheus_http_response_size_bytes_count{handler="/api/v1/query_range"} 902
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="10000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="100000"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="1e+06"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="1e+07"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="1e+08"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="1e+09"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/rules",le="+Inf"} 2
prometheus_http_response_size_bytes_sum{handler="/api/v1/rules"} 42954
prometheus_http_response_size_bytes_count{handler="/api/v1/rules"} 2
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="10000"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="100000"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="1e+06"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="1e+07"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="1e+08"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="1e+09"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/series",le="+Inf"} 1
prometheus_http_response_size_bytes_sum{handler="/api/v1/series"} 3113
prometheus_http_response_size_bytes_count{handler="/api/v1/series"} 1
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="1000"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="10000"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="100000"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="1e+06"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="1e+07"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="1e+08"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="1e+09"} 4
prometheus_http_response_size_bytes_bucket{handler="/api/v1/status/buildinfo",le="+Inf"} 4
prometheus_http_response_size_bytes_sum{handler="/api/v1/status/buildinfo"} 740
prometheus_http_response_size_bytes_count{handler="/api/v1/status/buildinfo"} 4
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="10000"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100000"} 33164
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+06"} 33166
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+07"} 33166
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+08"} 33166
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+09"} 33166
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="+Inf"} 33166
prometheus_http_response_size_bytes_sum{handler="/metrics"} 6.7902201e+08
prometheus_http_response_size_bytes_count{handler="/metrics"} 33166
# HELP prometheus_notifications_alertmanagers_discovered The number of alertmanagers discovered and active.
# TYPE prometheus_notifications_alertmanagers_discovered gauge
prometheus_notifications_alertmanagers_discovered 3
# HELP prometheus_notifications_dropped_total Total number of alerts dropped due to errors when sending to Alertmanager.
# TYPE prometheus_notifications_dropped_total counter
prometheus_notifications_dropped_total 1
# HELP prometheus_notifications_errors_total Total number of errors sending alert notifications.
# TYPE prometheus_notifications_errors_total counter
prometheus_notifications_errors_total{alertmanager="http://10.42.0.20:9093/api/v2/alerts"} 0
prometheus_notifications_errors_total{alertmanager="http://10.42.0.21:9093/api/v2/alerts"} 0
prometheus_notifications_errors_total{alertmanager="http://10.42.1.23:9093/api/v2/alerts"} 0
# HELP prometheus_notifications_latency_seconds Latency quantiles for sending alert notifications.
# TYPE prometheus_notifications_latency_seconds summary
prometheus_notifications_latency_seconds{alertmanager="http://10.42.0.20:9093/api/v2/alerts",quantile="0.5"} 0.001841481
prometheus_notifications_latency_seconds{alertmanager="http://10.42.0.20:9093/api/v2/alerts",quantile="0.9"} 0.003369225
prometheus_notifications_latency_seconds{alertmanager="http://10.42.0.20:9093/api/v2/alerts",quantile="0.99"} 0.00606225
prometheus_notifications_latency_seconds_sum{alertmanager="http://10.42.0.20:9093/api/v2/alerts"} 69.50487706999982
prometheus_notifications_latency_seconds_count{alertmanager="http://10.42.0.20:9093/api/v2/alerts"} 26835
prometheus_notifications_latency_seconds{alertmanager="http://10.42.0.21:9093/api/v2/alerts",quantile="0.5"} 0.001746498
prometheus_notifications_latency_seconds{alertmanager="http://10.42.0.21:9093/api/v2/alerts",quantile="0.9"} 0.004383979
prometheus_notifications_latency_seconds{alertmanager="http://10.42.0.21:9093/api/v2/alerts",quantile="0.99"} 0.026483588
prometheus_notifications_latency_seconds_sum{alertmanager="http://10.42.0.21:9093/api/v2/alerts"} 73.07180168800016
prometheus_notifications_latency_seconds_count{alertmanager="http://10.42.0.21:9093/api/v2/alerts"} 26835
prometheus_notifications_latency_seconds{alertmanager="http://10.42.1.23:9093/api/v2/alerts",quantile="0.5"} 0.001359167
prometheus_notifications_latency_seconds{alertmanager="http://10.42.1.23:9093/api/v2/alerts",quantile="0.9"} 0.002455923
prometheus_notifications_latency_seconds{alertmanager="http://10.42.1.23:9093/api/v2/alerts",quantile="0.99"} 0.004335094
prometheus_notifications_latency_seconds_sum{alertmanager="http://10.42.1.23:9093/api/v2/alerts"} 57.534417425999855
prometheus_notifications_latency_seconds_count{alertmanager="http://10.42.1.23:9093/api/v2/alerts"} 26835
# HELP prometheus_notifications_queue_capacity The capacity of the alert notifications queue.
# TYPE prometheus_notifications_queue_capacity gauge
prometheus_notifications_queue_capacity 10000
# HELP prometheus_notifications_queue_length The number of alert notifications in the queue.
# TYPE prometheus_notifications_queue_length gauge
prometheus_notifications_queue_length 0
# HELP prometheus_notifications_sent_total Total number of alerts sent.
# TYPE prometheus_notifications_sent_total counter
prometheus_notifications_sent_total{alertmanager="http://10.42.0.20:9093/api/v2/alerts"} 89819
prometheus_notifications_sent_total{alertmanager="http://10.42.0.21:9093/api/v2/alerts"} 89819
prometheus_notifications_sent_total{alertmanager="http://10.42.1.23:9093/api/v2/alerts"} 89819
# HELP prometheus_ready Whether Prometheus startup was fully completed and the server is ready for normal operation.
# TYPE prometheus_ready gauge
prometheus_ready 1
# HELP prometheus_remote_storage_exemplars_in_total Exemplars in to remote storage, compare to exemplars out for queue managers.
# TYPE prometheus_remote_storage_exemplars_in_total counter
prometheus_remote_storage_exemplars_in_total 0
# HELP prometheus_remote_storage_highest_timestamp_in_seconds Highest timestamp that has come into the remote storage via the Appender interface, in seconds since epoch. Initialized to 0 when no data has been received yet.
# TYPE prometheus_remote_storage_highest_timestamp_in_seconds gauge
prometheus_remote_storage_highest_timestamp_in_seconds 1.728582244e+09
# HELP prometheus_remote_storage_histograms_in_total HistogramSamples in to remote storage, compare to histograms out for queue managers.
# TYPE prometheus_remote_storage_histograms_in_total counter
prometheus_remote_storage_histograms_in_total 0
# HELP prometheus_remote_storage_samples_in_total Samples in to remote storage, compare to samples out for queue managers.
# TYPE prometheus_remote_storage_samples_in_total counter
prometheus_remote_storage_samples_in_total 9.32902651e+08
# HELP prometheus_remote_storage_string_interner_zero_reference_releases_total The number of times release has been called for strings that are not interned.
# TYPE prometheus_remote_storage_string_interner_zero_reference_releases_total counter
prometheus_remote_storage_string_interner_zero_reference_releases_total 0
# HELP prometheus_rule_evaluation_duration_seconds The duration for a rule to execute.
# TYPE prometheus_rule_evaluation_duration_seconds summary
prometheus_rule_evaluation_duration_seconds{quantile="0.5"} 0.000504587
prometheus_rule_evaluation_duration_seconds{quantile="0.9"} 0.003858578
prometheus_rule_evaluation_duration_seconds{quantile="0.99"} 0.145810466
prometheus_rule_evaluation_duration_seconds_sum 6619.4980728337205
prometheus_rule_evaluation_duration_seconds_count 1.680319e+06
# HELP prometheus_rule_evaluation_failures_total The total number of rule evaluation failures.
# TYPE prometheus_rule_evaluation_failures_total counter
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 0
prometheus_rule_evaluation_failures_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 0
# HELP prometheus_rule_evaluations_total The total number of rule evaluations.
# TYPE prometheus_rule_evaluations_total counter
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 66328
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 8292
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 24873
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 16582
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 49746
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 33164
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 16582
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 16582
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 16582
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 16582
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 8292
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 33164
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 22112
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 116074
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 16582
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 33164
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 74619
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 24873
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 132656
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 66328
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 41455
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 16582
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 49746
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 107783
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 41460
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 207275
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 91201
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 190693
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 8291
prometheus_rule_evaluations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 66328
# HELP prometheus_rule_group_duration_seconds The duration of rule group evaluations.
# TYPE prometheus_rule_group_duration_seconds summary
prometheus_rule_group_duration_seconds{quantile="0.01"} 0.000459629
prometheus_rule_group_duration_seconds{quantile="0.05"} 0.000711042
prometheus_rule_group_duration_seconds{quantile="0.5"} 0.003219787
prometheus_rule_group_duration_seconds{quantile="0.9"} 0.012834104
prometheus_rule_group_duration_seconds{quantile="0.99"} 0.665778802
prometheus_rule_group_duration_seconds_sum 6638.6166713082475
prometheus_rule_group_duration_seconds_count 308152
# HELP prometheus_rule_group_interval_seconds The interval of a rule group.
# TYPE prometheus_rule_group_interval_seconds gauge
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 180
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 30
prometheus_rule_group_interval_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 30
# HELP prometheus_rule_group_iterations_missed_total The total number of rule group evaluations missed due to slow rule group evaluation.
# TYPE prometheus_rule_group_iterations_missed_total counter
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 0
prometheus_rule_group_iterations_missed_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 0
# HELP prometheus_rule_group_iterations_total The total number of scheduled rule group evaluations, whether executed or missed.
# TYPE prometheus_rule_group_iterations_total counter
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 8292
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 8292
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 1382
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 8292
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 8291
prometheus_rule_group_iterations_total{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 8291
# HELP prometheus_rule_group_last_duration_seconds The duration of the last rule group evaluation.
# TYPE prometheus_rule_group_last_duration_seconds gauge
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 0.010778462
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 0.002358138
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 0.002858595
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 0.004650018
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 0.002191264
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 0.004008137
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 0.000681918
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 0.003415737
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 0.00416134
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 0.00376148
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 0.003459707
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 0.002308948
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 0.003753113
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 0.002948726
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 0.003131152
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 0.003509208
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 0.00312667
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 0.003129755
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 0.237069148
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 0.724710496
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 0.046996938
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 0.00130508
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 0.00199098
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 0.003090631
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 0.013200554
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 0.007280799
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 0.005530966
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 0.001490696
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 0.007372795
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 0.000654575
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 0.005079595
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 0.000767488
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 0.005388943
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 0.041687229
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 0.00471427
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 0.011460246
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 0.001037764
prometheus_rule_group_last_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 0.003410207
# HELP prometheus_rule_group_last_evaluation_samples The number of samples returned during the last rule group evaluation.
# TYPE prometheus_rule_group_last_evaluation_samples gauge
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 100
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 16
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 24
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 10
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 24
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 27
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 90
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 90
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 26
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 29
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 90
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 90
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 90
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 39
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 700
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 7
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 17
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 6
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 22
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 14
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 2
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 2
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 44
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 22
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 0
prometheus_rule_group_last_evaluation_samples{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 0
# HELP prometheus_rule_group_last_evaluation_timestamp_seconds The timestamp of the last rule group evaluation in seconds.
# TYPE prometheus_rule_group_last_evaluation_timestamp_seconds gauge
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 1.728582216425946e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 1.7285822275474405e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 1.728582240595834e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 1.728582218155257e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 1.7285822240732121e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 1.7285822202752361e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 1.7285822342820923e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 1.728582229058993e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 1.7285822302557263e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 1.7285822344800713e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 1.7285822204606216e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 1.7285822167398186e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 1.728582219981496e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 1.728582222772913e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 1.728582244168197e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 1.7285822273611295e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 1.728582231342025e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 1.728582234866057e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 1.7285821867496846e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 1.728582234048922e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 1.728582232045477e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 1.7285822361921692e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 1.728582238653852e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 1.7285822321728067e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 1.728582232630707e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 1.7285822167633142e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 1.7285822164602587e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 1.728582222520895e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 1.7285822380807247e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 1.7285822323868303e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 1.7285822342539115e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 1.7285822233017633e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 1.7285822425809293e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 1.728582239325559e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 1.7285822222373211e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 1.728582235915716e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 1.7285822246624894e+09
prometheus_rule_group_last_evaluation_timestamp_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 1.728582233072563e+09
# HELP prometheus_rule_group_last_restore_duration_seconds The duration of the last alert rules alerts restoration using the `ALERTS_FOR_STATE` series.
# TYPE prometheus_rule_group_last_restore_duration_seconds gauge
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 2.2151e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 4.191e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 2.306e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 1.4794e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 3.948e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 3.331e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 7.328e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 2.6705e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 7.482e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 8.777e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 3.612e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 8.571e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 5.909e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 3.522e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 7.453e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 5.64e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 6.074e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 5.097e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 2.672e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 3.838e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 5.872e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 2.2001e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 3.184e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 5.611e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 0.000137601
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 4.2917e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 2.4384e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 1.5973e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 2.4126e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 2.1713e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 5.3529e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 1.4912e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 2.76e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 8.6083e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 3.129e-06
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 0.000108886
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 2.0283e-05
prometheus_rule_group_last_restore_duration_seconds{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 4.3347e-05
# HELP prometheus_rule_group_rules The number of rules.
# TYPE prometheus_rule_group_rules gauge
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-alertmanager-main-rules-869ece1e-66b8-48fb-9910-22b7d9c6eb71.yaml;alertmanager.rules"} 8
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;GrafanaAlerts"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-grafana-rules-bc951fe4-1fc3-4801-9ab7-8cb319ccd8fa.yaml;grafana_rules"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;general.rules"} 3
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-general.rules"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;kube-prometheus-node-recording.rules"} 6
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-prometheus-rules-5ed958f0-cc46-4aa7-a067-e0c2c8263305.yaml;node-network"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kube-state-metrics-rules-1f5bf21a-8321-436b-a97f-effe1b4a4e9c.yaml;kube-state-metrics"} 4
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_limits"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_requests"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_cpu_usage_seconds_total"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_cache"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_limits"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_requests"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_rss"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_swap"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.container_memory_working_set_bytes"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;k8s.rules.pod_owner"} 4
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-availability.rules"} 16
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-burnrate.rules"} 14
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-histogram.rules"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-apiserver-slos"} 4
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kube-scheduler.rules"} 9
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubelet.rules"} 3
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-apps"} 16
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-resources"} 8
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-storage"} 5
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system"} 2
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-apiserver"} 6
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-controller-manager"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-kubelet"} 13
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;kubernetes-system-scheduler"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-kubernetes-monitoring-rules-df29d5d3-abf8-4cca-ae99-bd88c58f1c8e.yaml;node.rules"} 5
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter"} 25
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-node-exporter-rules-18417dc6-ae86-4835-ae9e-cb68728cbe89.yaml;node-exporter.rules"} 11
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-k8s-prometheus-rules-614343d2-ac58-4449-866c-5803063b87b7.yaml;prometheus"} 23
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;config-reloaders"} 1
prometheus_rule_group_rules{rule_group="/etc/prometheus/rules/prometheus-k8s-rulefiles-0/monitoring-prometheus-operator-rules-0d765f44-8a57-49b1-af03-73e776facafe.yaml;prometheus-operator"} 8
# HELP prometheus_sd_azure_cache_hit_total Number of cache hit during refresh.
# TYPE prometheus_sd_azure_cache_hit_total counter
prometheus_sd_azure_cache_hit_total 0
# HELP prometheus_sd_azure_failures_total Number of Azure service discovery refresh failures.
# TYPE prometheus_sd_azure_failures_total counter
prometheus_sd_azure_failures_total 0
# HELP prometheus_sd_consul_rpc_duration_seconds The duration of a Consul RPC call in seconds.
# TYPE prometheus_sd_consul_rpc_duration_seconds summary
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="services",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="services",endpoint="catalog"} 0
# HELP prometheus_sd_consul_rpc_failures_total The number of Consul RPC call failures.
# TYPE prometheus_sd_consul_rpc_failures_total counter
prometheus_sd_consul_rpc_failures_total 0
# HELP prometheus_sd_discovered_targets Current number of discovered targets.
# TYPE prometheus_sd_discovered_targets gauge
prometheus_sd_discovered_targets{config="config-0",name="notify"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/default/open5gs-amf/0",name="scrape"} 57
prometheus_sd_discovered_targets{config="serviceMonitor/default/open5gs-pcf/0",name="scrape"} 57
prometheus_sd_discovered_targets{config="serviceMonitor/default/open5gs-smf/0",name="scrape"} 57
prometheus_sd_discovered_targets{config="serviceMonitor/default/open5gs-upf/0",name="scrape"} 57
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/alertmanager-main/0",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/alertmanager-main/1",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/blackbox-exporter/0",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/coredns/0",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/grafana/0",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-apiserver/0",name="scrape"} 57
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-apiserver/1",name="scrape"} 57
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-controller-manager/0",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-controller-manager/1",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-scheduler/0",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-scheduler/1",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-state-metrics/0",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kube-state-metrics/1",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kubelet/0",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kubelet/1",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kubelet/2",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/kubelet/3",name="scrape"} 14
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/node-exporter/0",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/prometheus-adapter/0",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/prometheus-k8s/0",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/prometheus-k8s/1",name="scrape"} 48
prometheus_sd_discovered_targets{config="serviceMonitor/monitoring/prometheus-operator/0",name="scrape"} 48
# HELP prometheus_sd_dns_lookup_failures_total The number of DNS-SD lookup failures.
# TYPE prometheus_sd_dns_lookup_failures_total counter
prometheus_sd_dns_lookup_failures_total 0
# HELP prometheus_sd_dns_lookups_total The number of DNS-SD lookups.
# TYPE prometheus_sd_dns_lookups_total counter
prometheus_sd_dns_lookups_total 0
# HELP prometheus_sd_failed_configs Current number of service discovery configurations that failed to load.
# TYPE prometheus_sd_failed_configs gauge
prometheus_sd_failed_configs{name="notify"} 0
prometheus_sd_failed_configs{name="scrape"} 0
# HELP prometheus_sd_file_read_errors_total The number of File-SD read errors.
# TYPE prometheus_sd_file_read_errors_total counter
prometheus_sd_file_read_errors_total 0
# HELP prometheus_sd_file_scan_duration_seconds The duration of the File-SD scan in seconds.
# TYPE prometheus_sd_file_scan_duration_seconds summary
prometheus_sd_file_scan_duration_seconds{quantile="0.5"} NaN
prometheus_sd_file_scan_duration_seconds{quantile="0.9"} NaN
prometheus_sd_file_scan_duration_seconds{quantile="0.99"} NaN
prometheus_sd_file_scan_duration_seconds_sum 0
prometheus_sd_file_scan_duration_seconds_count 0
# HELP prometheus_sd_file_watcher_errors_total The number of File-SD errors caused by filesystem watch failures.
# TYPE prometheus_sd_file_watcher_errors_total counter
prometheus_sd_file_watcher_errors_total 0
# HELP prometheus_sd_http_failures_total Number of HTTP service discovery refresh failures.
# TYPE prometheus_sd_http_failures_total counter
prometheus_sd_http_failures_total 0
# HELP prometheus_sd_kubernetes_events_total The number of Kubernetes events handled.
# TYPE prometheus_sd_kubernetes_events_total counter
prometheus_sd_kubernetes_events_total{event="add",role="endpoints"} 272
prometheus_sd_kubernetes_events_total{event="add",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="add",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="add",role="node"} 0
prometheus_sd_kubernetes_events_total{event="add",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="add",role="service"} 272
prometheus_sd_kubernetes_events_total{event="delete",role="endpoints"} 42
prometheus_sd_kubernetes_events_total{event="delete",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="node"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="pod"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="service"} 42
prometheus_sd_kubernetes_events_total{event="update",role="endpoints"} 83
prometheus_sd_kubernetes_events_total{event="update",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="update",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="update",role="node"} 0
prometheus_sd_kubernetes_events_total{event="update",role="pod"} 342
prometheus_sd_kubernetes_events_total{event="update",role="service"} 0
# HELP prometheus_sd_kubernetes_failures_total The number of failed WATCH/LIST requests.
# TYPE prometheus_sd_kubernetes_failures_total counter
prometheus_sd_kubernetes_failures_total 0
# HELP prometheus_sd_kubernetes_http_request_duration_seconds Summary of latencies for HTTP requests to the Kubernetes API by endpoint.
# TYPE prometheus_sd_kubernetes_http_request_duration_seconds summary
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/namespaces/%7Bnamespace%7D/endpoints"} 0.21112523900000002
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/namespaces/%7Bnamespace%7D/endpoints"} 20
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/namespaces/%7Bnamespace%7D/pods"} 0.272766808
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/namespaces/%7Bnamespace%7D/pods"} 20
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/namespaces/%7Bnamespace%7D/services"} 0.262303111
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/namespaces/%7Bnamespace%7D/services"} 20
# HELP prometheus_sd_kubernetes_http_request_total Total number of HTTP requests to the Kubernetes API by status code.
# TYPE prometheus_sd_kubernetes_http_request_total counter
prometheus_sd_kubernetes_http_request_total{status_code="200"} 6740
# HELP prometheus_sd_kubernetes_workqueue_depth Current depth of the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_depth gauge
prometheus_sd_kubernetes_workqueue_depth{queue_name="endpoints"} 0
# HELP prometheus_sd_kubernetes_workqueue_items_total Total number of items added to the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_items_total counter
prometheus_sd_kubernetes_workqueue_items_total{queue_name="endpoints"} 447
# HELP prometheus_sd_kubernetes_workqueue_latency_seconds How long an item stays in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_latency_seconds summary
prometheus_sd_kubernetes_workqueue_latency_seconds_sum{queue_name="endpoints"} 20.927634817999998
prometheus_sd_kubernetes_workqueue_latency_seconds_count{queue_name="endpoints"} 447
# HELP prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds Duration of the longest running processor in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds gauge
prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds{queue_name="endpoints"} 0
# HELP prometheus_sd_kubernetes_workqueue_unfinished_work_seconds How long an item has remained unfinished in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_unfinished_work_seconds gauge
prometheus_sd_kubernetes_workqueue_unfinished_work_seconds{queue_name="endpoints"} 0
# HELP prometheus_sd_kubernetes_workqueue_work_duration_seconds How long processing an item from the work queue takes.
# TYPE prometheus_sd_kubernetes_workqueue_work_duration_seconds summary
prometheus_sd_kubernetes_workqueue_work_duration_seconds_sum{queue_name="endpoints"} 0.11674285700000006
prometheus_sd_kubernetes_workqueue_work_duration_seconds_count{queue_name="endpoints"} 447
# HELP prometheus_sd_kuma_fetch_duration_seconds The duration of a Kuma MADS fetch call.
# TYPE prometheus_sd_kuma_fetch_duration_seconds summary
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.5"} NaN
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.9"} NaN
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.99"} NaN
prometheus_sd_kuma_fetch_duration_seconds_sum 0
prometheus_sd_kuma_fetch_duration_seconds_count 0
# HELP prometheus_sd_kuma_fetch_failures_total The number of Kuma MADS fetch call failures.
# TYPE prometheus_sd_kuma_fetch_failures_total counter
prometheus_sd_kuma_fetch_failures_total 0
# HELP prometheus_sd_kuma_fetch_skipped_updates_total The number of Kuma MADS fetch calls that result in no updates to the targets.
# TYPE prometheus_sd_kuma_fetch_skipped_updates_total counter
prometheus_sd_kuma_fetch_skipped_updates_total 0
# HELP prometheus_sd_linode_failures_total Number of Linode service discovery refresh failures.
# TYPE prometheus_sd_linode_failures_total counter
prometheus_sd_linode_failures_total 0
# HELP prometheus_sd_nomad_failures_total Number of nomad service discovery refresh failures.
# TYPE prometheus_sd_nomad_failures_total counter
prometheus_sd_nomad_failures_total 0
# HELP prometheus_sd_received_updates_total Total number of update events received from the SD providers.
# TYPE prometheus_sd_received_updates_total counter
prometheus_sd_received_updates_total{name="notify"} 78
prometheus_sd_received_updates_total{name="scrape"} 369
# HELP prometheus_sd_updates_delayed_total Total number of update events that couldn't be sent immediately.
# TYPE prometheus_sd_updates_delayed_total counter
prometheus_sd_updates_delayed_total{name="notify"} 0
prometheus_sd_updates_delayed_total{name="scrape"} 0
# HELP prometheus_sd_updates_total Total number of update events sent to the SD consumers.
# TYPE prometheus_sd_updates_total counter
prometheus_sd_updates_total{name="notify"} 9
prometheus_sd_updates_total{name="scrape"} 22
# HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.
# TYPE prometheus_target_interval_length_seconds summary
prometheus_target_interval_length_seconds{interval="15s",quantile="0.01"} 14.998720278
prometheus_target_interval_length_seconds{interval="15s",quantile="0.05"} 14.999189165
prometheus_target_interval_length_seconds{interval="15s",quantile="0.5"} 15.000044065
prometheus_target_interval_length_seconds{interval="15s",quantile="0.9"} 15.000663973
prometheus_target_interval_length_seconds{interval="15s",quantile="0.99"} 15.001167384
prometheus_target_interval_length_seconds_sum{interval="15s"} 1.2436058556089671e+06
prometheus_target_interval_length_seconds_count{interval="15s"} 82907
prometheus_target_interval_length_seconds{interval="30s",quantile="0.01"} 29.998974609
prometheus_target_interval_length_seconds{interval="30s",quantile="0.05"} 29.999174978
prometheus_target_interval_length_seconds{interval="30s",quantile="0.5"} 30.000027034
prometheus_target_interval_length_seconds{interval="30s",quantile="0.9"} 30.000609993
prometheus_target_interval_length_seconds{interval="30s",quantile="0.99"} 30.001400232
prometheus_target_interval_length_seconds_sum{interval="30s"} 6.77484262263696e+06
prometheus_target_interval_length_seconds_count{interval="30s"} 225828
prometheus_target_interval_length_seconds{interval="5s",quantile="0.01"} 4.998986443
prometheus_target_interval_length_seconds{interval="5s",quantile="0.05"} 4.999202052
prometheus_target_interval_length_seconds{interval="5s",quantile="0.5"} 5.000029908
prometheus_target_interval_length_seconds{interval="5s",quantile="0.9"} 5.000625921
prometheus_target_interval_length_seconds{interval="5s",quantile="0.99"} 5.000942866
prometheus_target_interval_length_seconds_sum{interval="5s"} 746176.6167480407
prometheus_target_interval_length_seconds_count{interval="5s"} 149235
# HELP prometheus_target_metadata_cache_bytes The number of bytes that are currently used for storing metric metadata in the cache
# TYPE prometheus_target_metadata_cache_bytes gauge
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/default/open5gs-amf/0"} 1706
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 534
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/default/open5gs-smf/0"} 1686
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/default/open5gs-upf/0"} 849
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 17583
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 7263
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 2098
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/coredns/0"} 3333
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/grafana/0"} 55692
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 45856
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 203
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 0
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 0
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 0
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 0
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 13280
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 2335
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kubelet/0"} 74490
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kubelet/1"} 6898
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kubelet/2"} 452
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/kubelet/3"} 270
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 26916
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 38898
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 68876
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 9684
prometheus_target_metadata_cache_bytes{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 5335
# HELP prometheus_target_metadata_cache_entries Total number of metric metadata entries in the cache
# TYPE prometheus_target_metadata_cache_entries gauge
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/default/open5gs-amf/0"} 31
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 12
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/default/open5gs-smf/0"} 34
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/default/open5gs-upf/0"} 17
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 309
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 138
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 40
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/coredns/0"} 61
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/grafana/0"} 672
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 438
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 3
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 0
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 0
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 0
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 0
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 212
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 43
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kubelet/0"} 700
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kubelet/1"} 138
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kubelet/2"} 6
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/kubelet/3"} 4
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 566
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 318
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 952
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 184
prometheus_target_metadata_cache_entries{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 65
# HELP prometheus_target_scrape_pool_exceeded_label_limits_total Total number of times scrape pools hit the label limits, during sync or config reload.
# TYPE prometheus_target_scrape_pool_exceeded_label_limits_total counter
prometheus_target_scrape_pool_exceeded_label_limits_total 0
# HELP prometheus_target_scrape_pool_exceeded_target_limit_total Total number of times scrape pools hit the target limit, during sync or config reload.
# TYPE prometheus_target_scrape_pool_exceeded_target_limit_total counter
prometheus_target_scrape_pool_exceeded_target_limit_total 0
# HELP prometheus_target_scrape_pool_reloads_failed_total Total number of failed scrape pool reloads.
# TYPE prometheus_target_scrape_pool_reloads_failed_total counter
prometheus_target_scrape_pool_reloads_failed_total 0
# HELP prometheus_target_scrape_pool_reloads_total Total number of scrape pool reloads.
# TYPE prometheus_target_scrape_pool_reloads_total counter
prometheus_target_scrape_pool_reloads_total 0
# HELP prometheus_target_scrape_pool_symboltable_items Current number of symbols in table for this scrape pool.
# TYPE prometheus_target_scrape_pool_symboltable_items gauge
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/default/open5gs-amf/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/default/open5gs-smf/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/default/open5gs-upf/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/coredns/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/grafana/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kubelet/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kubelet/1"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kubelet/2"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/kubelet/3"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 0
prometheus_target_scrape_pool_symboltable_items{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 0
# HELP prometheus_target_scrape_pool_sync_total Total number of syncs that were executed on a scrape pool.
# TYPE prometheus_target_scrape_pool_sync_total counter
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/default/open5gs-amf/0"} 4
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 4
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/default/open5gs-smf/0"} 4
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/default/open5gs-upf/0"} 4
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/coredns/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/grafana/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kubelet/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kubelet/1"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kubelet/2"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/kubelet/3"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 22
prometheus_target_scrape_pool_sync_total{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 22
# HELP prometheus_target_scrape_pool_target_limit Maximum number of targets allowed in this scrape pool.
# TYPE prometheus_target_scrape_pool_target_limit gauge
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/default/open5gs-amf/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/default/open5gs-smf/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/default/open5gs-upf/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/coredns/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/grafana/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kubelet/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kubelet/1"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kubelet/2"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/kubelet/3"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 0
prometheus_target_scrape_pool_target_limit{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 0
# HELP prometheus_target_scrape_pool_targets Current number of targets in this scrape pool.
# TYPE prometheus_target_scrape_pool_targets gauge
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/default/open5gs-amf/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/default/open5gs-smf/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/default/open5gs-upf/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 3
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 3
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/coredns/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/grafana/0"} 2
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 0
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 0
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 0
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 0
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 1
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kubelet/0"} 2
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kubelet/1"} 2
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kubelet/2"} 2
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/kubelet/3"} 2
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 2
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 2
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 4
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 4
prometheus_target_scrape_pool_targets{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 1
# HELP prometheus_target_scrape_pools_failed_total Total number of scrape pool creations that failed.
# TYPE prometheus_target_scrape_pools_failed_total counter
prometheus_target_scrape_pools_failed_total 0
# HELP prometheus_target_scrape_pools_total Total number of scrape pool creation attempts.
# TYPE prometheus_target_scrape_pools_total counter
prometheus_target_scrape_pools_total 30
# HELP prometheus_target_scrapes_cache_flush_forced_total How many times a scrape cache was flushed due to getting big while scrapes are failing.
# TYPE prometheus_target_scrapes_cache_flush_forced_total counter
prometheus_target_scrapes_cache_flush_forced_total 0
# HELP prometheus_target_scrapes_exceeded_body_size_limit_total Total number of scrapes that hit the body size limit
# TYPE prometheus_target_scrapes_exceeded_body_size_limit_total counter
prometheus_target_scrapes_exceeded_body_size_limit_total 0
# HELP prometheus_target_scrapes_exceeded_native_histogram_bucket_limit_total Total number of scrapes that hit the native histogram bucket limit and were rejected.
# TYPE prometheus_target_scrapes_exceeded_native_histogram_bucket_limit_total counter
prometheus_target_scrapes_exceeded_native_histogram_bucket_limit_total 0
# HELP prometheus_target_scrapes_exceeded_sample_limit_total Total number of scrapes that hit the sample limit and were rejected.
# TYPE prometheus_target_scrapes_exceeded_sample_limit_total counter
prometheus_target_scrapes_exceeded_sample_limit_total 0
# HELP prometheus_target_scrapes_exemplar_out_of_order_total Total number of exemplar rejected due to not being out of the expected order.
# TYPE prometheus_target_scrapes_exemplar_out_of_order_total counter
prometheus_target_scrapes_exemplar_out_of_order_total 0
# HELP prometheus_target_scrapes_sample_duplicate_timestamp_total Total number of samples rejected due to duplicate timestamps but different values.
# TYPE prometheus_target_scrapes_sample_duplicate_timestamp_total counter
prometheus_target_scrapes_sample_duplicate_timestamp_total 0
# HELP prometheus_target_scrapes_sample_out_of_bounds_total Total number of samples rejected due to timestamp falling outside of the time bounds.
# TYPE prometheus_target_scrapes_sample_out_of_bounds_total counter
prometheus_target_scrapes_sample_out_of_bounds_total 0
# HELP prometheus_target_scrapes_sample_out_of_order_total Total number of samples rejected due to not being out of the expected order.
# TYPE prometheus_target_scrapes_sample_out_of_order_total counter
prometheus_target_scrapes_sample_out_of_order_total 0
# HELP prometheus_target_sync_failed_total Total number of target sync failures.
# TYPE prometheus_target_sync_failed_total counter
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/default/open5gs-amf/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/default/open5gs-smf/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/default/open5gs-upf/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/coredns/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/grafana/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kubelet/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kubelet/1"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kubelet/2"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/kubelet/3"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 0
prometheus_target_sync_failed_total{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 0
# HELP prometheus_target_sync_length_seconds Actual interval to sync the scrape pool.
# TYPE prometheus_target_sync_length_seconds summary
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-amf/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-amf/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-amf/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-amf/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-amf/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/default/open5gs-amf/0"} 0.01136864
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/default/open5gs-amf/0"} 4
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-pcf/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-pcf/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-pcf/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-pcf/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-pcf/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 0.010866062000000001
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/default/open5gs-pcf/0"} 4
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-smf/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-smf/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-smf/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-smf/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-smf/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/default/open5gs-smf/0"} 0.019377730000000003
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/default/open5gs-smf/0"} 4
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-upf/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-upf/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-upf/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-upf/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/default/open5gs-upf/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/default/open5gs-upf/0"} 0.011263592
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/default/open5gs-upf/0"} 4
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 0.055355582
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/alertmanager-main/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/1",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/1",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/1",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/1",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/alertmanager-main/1",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 0.061660599
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/alertmanager-main/1"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 0.057354361
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/blackbox-exporter/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/coredns/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/coredns/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/coredns/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/coredns/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/coredns/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/coredns/0"} 0.011259281999999999
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/coredns/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/grafana/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/grafana/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/grafana/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/grafana/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/grafana/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/grafana/0"} 6.411279095000001
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/grafana/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 0.054934473
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-apiserver/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/1",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/1",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/1",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/1",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-apiserver/1",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 0.053639956000000016
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-apiserver/1"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 0.015488644999999999
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-controller-manager/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 0.016855894
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-controller-manager/1"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 0.013999114999999998
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-scheduler/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/1",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/1",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/1",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/1",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-scheduler/1",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 0.013162375
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-scheduler/1"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 0.05350569999999999
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-state-metrics/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 0.05838974599999999
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kube-state-metrics/1"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kubelet/0"} 0.014671666
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kubelet/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/1",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/1",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/1",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/1",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/1",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kubelet/1"} 0.025826631
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kubelet/1"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/2",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/2",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/2",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/2",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/2",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kubelet/2"} 0.018113966
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kubelet/2"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/3",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/3",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/3",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/3",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/kubelet/3",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/kubelet/3"} 0.017968423999999997
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/kubelet/3"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/node-exporter/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/node-exporter/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/node-exporter/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/node-exporter/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/node-exporter/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 0.04648063300000001
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/node-exporter/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 0.05654332800000001
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/prometheus-adapter/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 0.060798567
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/prometheus-k8s/0"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 0.049640891000000006
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/prometheus-k8s/1"} 22
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-operator/0",quantile="0.01"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-operator/0",quantile="0.05"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-operator/0",quantile="0.5"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-operator/0",quantile="0.9"} NaN
prometheus_target_sync_length_seconds{scrape_job="serviceMonitor/monitoring/prometheus-operator/0",quantile="0.99"} NaN
prometheus_target_sync_length_seconds_sum{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 0.059582996000000006
prometheus_target_sync_length_seconds_count{scrape_job="serviceMonitor/monitoring/prometheus-operator/0"} 22
# HELP prometheus_template_text_expansion_failures_total The total number of template text expansion failures.
# TYPE prometheus_template_text_expansion_failures_total counter
prometheus_template_text_expansion_failures_total 0
# HELP prometheus_template_text_expansions_total The total number of template text expansions.
# TYPE prometheus_template_text_expansions_total counter
prometheus_template_text_expansions_total 1.012676e+06
# HELP prometheus_treecache_watcher_goroutines The current number of watcher goroutines.
# TYPE prometheus_treecache_watcher_goroutines gauge
prometheus_treecache_watcher_goroutines 0
# HELP prometheus_treecache_zookeeper_failures_total The total number of ZooKeeper failures.
# TYPE prometheus_treecache_zookeeper_failures_total counter
prometheus_treecache_zookeeper_failures_total 0
# HELP prometheus_tsdb_blocks_loaded Number of currently loaded data blocks
# TYPE prometheus_tsdb_blocks_loaded gauge
prometheus_tsdb_blocks_loaded 12
# HELP prometheus_tsdb_checkpoint_creations_failed_total Total number of checkpoint creations that failed.
# TYPE prometheus_tsdb_checkpoint_creations_failed_total counter
prometheus_tsdb_checkpoint_creations_failed_total 0
# HELP prometheus_tsdb_checkpoint_creations_total Total number of checkpoint creations attempted.
# TYPE prometheus_tsdb_checkpoint_creations_total counter
prometheus_tsdb_checkpoint_creations_total 32
# HELP prometheus_tsdb_checkpoint_deletions_failed_total Total number of checkpoint deletions that failed.
# TYPE prometheus_tsdb_checkpoint_deletions_failed_total counter
prometheus_tsdb_checkpoint_deletions_failed_total 0
# HELP prometheus_tsdb_checkpoint_deletions_total Total number of checkpoint deletions attempted.
# TYPE prometheus_tsdb_checkpoint_deletions_total counter
prometheus_tsdb_checkpoint_deletions_total 32
# HELP prometheus_tsdb_clean_start -1: lockfile is disabled. 0: a lockfile from a previous execution was replaced. 1: lockfile creation was clean
# TYPE prometheus_tsdb_clean_start gauge
prometheus_tsdb_clean_start 1
# HELP prometheus_tsdb_compaction_chunk_range_seconds Final time range of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_range_seconds histogram
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="100"} 33
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="400"} 33
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1600"} 33
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6400"} 33
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="25600"} 35
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="102400"} 356
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="409600"} 5279
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1.6384e+06"} 129121
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6.5536e+06"} 7.541183e+06
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="2.62144e+07"} 7.564686e+06
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="+Inf"} 7.564686e+06
prometheus_tsdb_compaction_chunk_range_seconds_sum 2.5388789028702e+13
prometheus_tsdb_compaction_chunk_range_seconds_count 7.564686e+06
# HELP prometheus_tsdb_compaction_chunk_samples Final number of samples on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_samples histogram
prometheus_tsdb_compaction_chunk_samples_bucket{le="4"} 400
prometheus_tsdb_compaction_chunk_samples_bucket{le="6"} 468
prometheus_tsdb_compaction_chunk_samples_bucket{le="9"} 1485
prometheus_tsdb_compaction_chunk_samples_bucket{le="13.5"} 3261
prometheus_tsdb_compaction_chunk_samples_bucket{le="20.25"} 3440
prometheus_tsdb_compaction_chunk_samples_bucket{le="30.375"} 9962
prometheus_tsdb_compaction_chunk_samples_bucket{le="45.5625"} 33412
prometheus_tsdb_compaction_chunk_samples_bucket{le="68.34375"} 36772
prometheus_tsdb_compaction_chunk_samples_bucket{le="102.515625"} 38879
prometheus_tsdb_compaction_chunk_samples_bucket{le="153.7734375"} 7.463984e+06
prometheus_tsdb_compaction_chunk_samples_bucket{le="230.66015625"} 7.56467e+06
prometheus_tsdb_compaction_chunk_samples_bucket{le="345.990234375"} 7.564686e+06
prometheus_tsdb_compaction_chunk_samples_bucket{le="+Inf"} 7.564686e+06
prometheus_tsdb_compaction_chunk_samples_sum 9.09136519e+08
prometheus_tsdb_compaction_chunk_samples_count 7.564686e+06
# HELP prometheus_tsdb_compaction_chunk_size_bytes Final size of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_size_bytes histogram
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="32"} 14775
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="48"} 261236
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="72"} 5.445061e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="108"} 6.032211e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="162"} 6.507383e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="243"} 7.05183e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="364.5"} 7.301157e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="546.75"} 7.372976e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="820.125"} 7.521434e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1230.1875"} 7.564686e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1845.28125"} 7.564686e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="2767.921875"} 7.564686e+06
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="+Inf"} 7.564686e+06
prometheus_tsdb_compaction_chunk_size_bytes_sum 7.55148679e+08
prometheus_tsdb_compaction_chunk_size_bytes_count 7.564686e+06
# HELP prometheus_tsdb_compaction_duration_seconds Duration of compaction runs
# TYPE prometheus_tsdb_compaction_duration_seconds histogram
prometheus_tsdb_compaction_duration_seconds_bucket{le="1"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="2"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="4"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="8"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="16"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="32"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="64"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="128"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="256"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="512"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="1024"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="2048"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="4096"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="8192"} 34
prometheus_tsdb_compaction_duration_seconds_bucket{le="+Inf"} 34
prometheus_tsdb_compaction_duration_seconds_sum 55.45156985399999
prometheus_tsdb_compaction_duration_seconds_count 34
# HELP prometheus_tsdb_compaction_populating_block Set to 1 when a block is currently being written to the disk.
# TYPE prometheus_tsdb_compaction_populating_block gauge
prometheus_tsdb_compaction_populating_block 0
# HELP prometheus_tsdb_compactions_failed_total Total number of compactions that failed for the partition.
# TYPE prometheus_tsdb_compactions_failed_total counter
prometheus_tsdb_compactions_failed_total 0
# HELP prometheus_tsdb_compactions_skipped_total Total number of skipped compactions due to disabled auto compaction.
# TYPE prometheus_tsdb_compactions_skipped_total counter
prometheus_tsdb_compactions_skipped_total 0
# HELP prometheus_tsdb_compactions_total Total number of compactions that were executed for the partition.
# TYPE prometheus_tsdb_compactions_total counter
prometheus_tsdb_compactions_total 34
# HELP prometheus_tsdb_compactions_triggered_total Total number of triggered compactions for the partition.
# TYPE prometheus_tsdb_compactions_triggered_total counter
prometheus_tsdb_compactions_triggered_total 4181
# HELP prometheus_tsdb_data_replay_duration_seconds Time taken to replay the data on disk.
# TYPE prometheus_tsdb_data_replay_duration_seconds gauge
prometheus_tsdb_data_replay_duration_seconds 0.000386546
# HELP prometheus_tsdb_exemplar_exemplars_appended_total Total number of appended exemplars.
# TYPE prometheus_tsdb_exemplar_exemplars_appended_total counter
prometheus_tsdb_exemplar_exemplars_appended_total 0
# HELP prometheus_tsdb_exemplar_exemplars_in_storage Number of exemplars currently in circular storage.
# TYPE prometheus_tsdb_exemplar_exemplars_in_storage gauge
prometheus_tsdb_exemplar_exemplars_in_storage 0
# HELP prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds The timestamp of the oldest exemplar stored in circular storage. Useful to check for what timerange the current exemplar buffer limit allows. This usually means the last timestampfor all exemplars for a typical setup. This is not true though if one of the series timestamp is in future compared to rest series.
# TYPE prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds gauge
prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds 0
# HELP prometheus_tsdb_exemplar_max_exemplars Total number of exemplars the exemplar storage can store, resizeable.
# TYPE prometheus_tsdb_exemplar_max_exemplars gauge
prometheus_tsdb_exemplar_max_exemplars 0
# HELP prometheus_tsdb_exemplar_out_of_order_exemplars_total Total number of out of order exemplar ingestion failed attempts.
# TYPE prometheus_tsdb_exemplar_out_of_order_exemplars_total counter
prometheus_tsdb_exemplar_out_of_order_exemplars_total 0
# HELP prometheus_tsdb_exemplar_series_with_exemplars_in_storage Number of series with exemplars currently in circular storage.
# TYPE prometheus_tsdb_exemplar_series_with_exemplars_in_storage gauge
prometheus_tsdb_exemplar_series_with_exemplars_in_storage 0
# HELP prometheus_tsdb_head_active_appenders Number of currently active appender transactions
# TYPE prometheus_tsdb_head_active_appenders gauge
prometheus_tsdb_head_active_appenders 0
# HELP prometheus_tsdb_head_chunks Total number of chunks in the head block.
# TYPE prometheus_tsdb_head_chunks gauge
prometheus_tsdb_head_chunks 228213
# HELP prometheus_tsdb_head_chunks_created_total Total number of chunks created in the head
# TYPE prometheus_tsdb_head_chunks_created_total counter
prometheus_tsdb_head_chunks_created_total 7.792899e+06
# HELP prometheus_tsdb_head_chunks_removed_total Total number of chunks removed in the head
# TYPE prometheus_tsdb_head_chunks_removed_total counter
prometheus_tsdb_head_chunks_removed_total 7.564686e+06
# HELP prometheus_tsdb_head_chunks_storage_size_bytes Size of the chunks_head directory.
# TYPE prometheus_tsdb_head_chunks_storage_size_bytes gauge
prometheus_tsdb_head_chunks_storage_size_bytes 4.6075113e+07
# HELP prometheus_tsdb_head_gc_duration_seconds Runtime of garbage collection in the head block.
# TYPE prometheus_tsdb_head_gc_duration_seconds summary
prometheus_tsdb_head_gc_duration_seconds_sum 2.303067719
prometheus_tsdb_head_gc_duration_seconds_count 34
# HELP prometheus_tsdb_head_max_time Maximum timestamp of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_max_time gauge
prometheus_tsdb_head_max_time 1.728582244166e+12
# HELP prometheus_tsdb_head_max_time_seconds Maximum timestamp of the head block.
# TYPE prometheus_tsdb_head_max_time_seconds gauge
prometheus_tsdb_head_max_time_seconds 1.728582244e+09
# HELP prometheus_tsdb_head_min_time Minimum time bound of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_min_time gauge
prometheus_tsdb_head_min_time 1.728576000063e+12
# HELP prometheus_tsdb_head_min_time_seconds Minimum time bound of the head block.
# TYPE prometheus_tsdb_head_min_time_seconds gauge
prometheus_tsdb_head_min_time_seconds 1.728576e+09
# HELP prometheus_tsdb_head_out_of_order_samples_appended_total Total number of appended out of order samples.
# TYPE prometheus_tsdb_head_out_of_order_samples_appended_total counter
prometheus_tsdb_head_out_of_order_samples_appended_total{type="float"} 0
# HELP prometheus_tsdb_head_samples_appended_total Total number of appended samples.
# TYPE prometheus_tsdb_head_samples_appended_total counter
prometheus_tsdb_head_samples_appended_total{type="float"} 9.32902651e+08
prometheus_tsdb_head_samples_appended_total{type="histogram"} 0
# HELP prometheus_tsdb_head_series Total number of series in the head block.
# TYPE prometheus_tsdb_head_series gauge
prometheus_tsdb_head_series 107063
# HELP prometheus_tsdb_head_series_created_total Total number of series created in the head
# TYPE prometheus_tsdb_head_series_created_total counter
prometheus_tsdb_head_series_created_total 115540
# HELP prometheus_tsdb_head_series_not_found_total Total number of requests for series that were not found.
# TYPE prometheus_tsdb_head_series_not_found_total counter
prometheus_tsdb_head_series_not_found_total 0
# HELP prometheus_tsdb_head_series_removed_total Total number of series removed in the head
# TYPE prometheus_tsdb_head_series_removed_total counter
prometheus_tsdb_head_series_removed_total 8477
# HELP prometheus_tsdb_head_truncations_failed_total Total number of head truncations that failed.
# TYPE prometheus_tsdb_head_truncations_failed_total counter
prometheus_tsdb_head_truncations_failed_total 0
# HELP prometheus_tsdb_head_truncations_total Total number of head truncations attempted.
# TYPE prometheus_tsdb_head_truncations_total counter
prometheus_tsdb_head_truncations_total 34
# HELP prometheus_tsdb_isolation_high_watermark The highest TSDB append ID that has been given out.
# TYPE prometheus_tsdb_isolation_high_watermark gauge
prometheus_tsdb_isolation_high_watermark 2.138333e+06
# HELP prometheus_tsdb_isolation_low_watermark The lowest TSDB append ID that is still referenced.
# TYPE prometheus_tsdb_isolation_low_watermark gauge
prometheus_tsdb_isolation_low_watermark 2.138333e+06
# HELP prometheus_tsdb_lowest_timestamp Lowest timestamp value stored in the database. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_lowest_timestamp gauge
prometheus_tsdb_lowest_timestamp 1.728489600063e+12
# HELP prometheus_tsdb_lowest_timestamp_seconds Lowest timestamp value stored in the database.
# TYPE prometheus_tsdb_lowest_timestamp_seconds gauge
prometheus_tsdb_lowest_timestamp_seconds 1.7284896e+09
# HELP prometheus_tsdb_mmap_chunk_corruptions_total Total number of memory-mapped chunk corruptions.
# TYPE prometheus_tsdb_mmap_chunk_corruptions_total counter
prometheus_tsdb_mmap_chunk_corruptions_total 0
# HELP prometheus_tsdb_mmap_chunks_total Total number of chunks that were memory-mapped.
# TYPE prometheus_tsdb_mmap_chunks_total counter
prometheus_tsdb_mmap_chunks_total 7.677359e+06
# HELP prometheus_tsdb_out_of_bound_samples_total Total number of out of bound samples ingestion failed attempts with out of order support disabled.
# TYPE prometheus_tsdb_out_of_bound_samples_total counter
prometheus_tsdb_out_of_bound_samples_total{type="float"} 0
# HELP prometheus_tsdb_out_of_order_samples_total Total number of out of order samples ingestion failed attempts due to out of order being disabled.
# TYPE prometheus_tsdb_out_of_order_samples_total counter
prometheus_tsdb_out_of_order_samples_total{type="float"} 0
prometheus_tsdb_out_of_order_samples_total{type="histogram"} 0
# HELP prometheus_tsdb_reloads_failures_total Number of times the database failed to reloadBlocks block data from disk.
# TYPE prometheus_tsdb_reloads_failures_total counter
prometheus_tsdb_reloads_failures_total 0
# HELP prometheus_tsdb_reloads_total Number of times the database reloaded block data from disk.
# TYPE prometheus_tsdb_reloads_total counter
prometheus_tsdb_reloads_total 4148
# HELP prometheus_tsdb_retention_limit_bytes Max number of bytes to be retained in the tsdb blocks, configured 0 means disabled
# TYPE prometheus_tsdb_retention_limit_bytes gauge
prometheus_tsdb_retention_limit_bytes 0
# HELP prometheus_tsdb_retention_limit_seconds How long to retain samples in storage.
# TYPE prometheus_tsdb_retention_limit_seconds gauge
prometheus_tsdb_retention_limit_seconds 86400
# HELP prometheus_tsdb_size_retentions_total The number of times that blocks were deleted because the maximum number of bytes was exceeded.
# TYPE prometheus_tsdb_size_retentions_total counter
prometheus_tsdb_size_retentions_total 0
# HELP prometheus_tsdb_snapshot_replay_error_total Total number snapshot replays that failed.
# TYPE prometheus_tsdb_snapshot_replay_error_total counter
prometheus_tsdb_snapshot_replay_error_total 0
# HELP prometheus_tsdb_storage_blocks_bytes The number of bytes that are currently used for local storage by all blocks.
# TYPE prometheus_tsdb_storage_blocks_bytes gauge
prometheus_tsdb_storage_blocks_bytes 4.62815005e+08
# HELP prometheus_tsdb_symbol_table_size_bytes Size of symbol table in memory for loaded blocks
# TYPE prometheus_tsdb_symbol_table_size_bytes gauge
prometheus_tsdb_symbol_table_size_bytes 15792
# HELP prometheus_tsdb_time_retentions_total The number of times that blocks were deleted because the maximum time limit was exceeded.
# TYPE prometheus_tsdb_time_retentions_total counter
prometheus_tsdb_time_retentions_total 22
# HELP prometheus_tsdb_tombstone_cleanup_seconds The time taken to recompact blocks to remove tombstones.
# TYPE prometheus_tsdb_tombstone_cleanup_seconds histogram
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_tombstone_cleanup_seconds_sum 0
prometheus_tsdb_tombstone_cleanup_seconds_count 0
# HELP prometheus_tsdb_too_old_samples_total Total number of out of order samples ingestion failed attempts with out of support enabled, but sample outside of time window.
# TYPE prometheus_tsdb_too_old_samples_total counter
prometheus_tsdb_too_old_samples_total{type="float"} 0
# HELP prometheus_tsdb_vertical_compactions_total Total number of compactions done on overlapping blocks.
# TYPE prometheus_tsdb_vertical_compactions_total counter
prometheus_tsdb_vertical_compactions_total 0
# HELP prometheus_tsdb_wal_completed_pages_total Total number of completed pages.
# TYPE prometheus_tsdb_wal_completed_pages_total counter
prometheus_tsdb_wal_completed_pages_total 145964
# HELP prometheus_tsdb_wal_corruptions_total Total number of WAL corruptions.
# TYPE prometheus_tsdb_wal_corruptions_total counter
prometheus_tsdb_wal_corruptions_total 0
# HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of write log fsync.
# TYPE prometheus_tsdb_wal_fsync_duration_seconds summary
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.5"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.9"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.99"} NaN
prometheus_tsdb_wal_fsync_duration_seconds_sum 0.15460551099999997
prometheus_tsdb_wal_fsync_duration_seconds_count 67
# HELP prometheus_tsdb_wal_page_flushes_total Total number of page flushes.
# TYPE prometheus_tsdb_wal_page_flushes_total counter
prometheus_tsdb_wal_page_flushes_total 1.115941e+06
# HELP prometheus_tsdb_wal_segment_current Write log segment index that TSDB is currently writing to.
# TYPE prometheus_tsdb_wal_segment_current gauge
prometheus_tsdb_wal_segment_current 67
# HELP prometheus_tsdb_wal_storage_size_bytes Size of the write log directory.
# TYPE prometheus_tsdb_wal_storage_size_bytes gauge
prometheus_tsdb_wal_storage_size_bytes 1.95273127e+08
# HELP prometheus_tsdb_wal_truncate_duration_seconds Duration of WAL truncation.
# TYPE prometheus_tsdb_wal_truncate_duration_seconds summary
prometheus_tsdb_wal_truncate_duration_seconds_sum 42.304392715
prometheus_tsdb_wal_truncate_duration_seconds_count 32
# HELP prometheus_tsdb_wal_truncations_failed_total Total number of write log truncations that failed.
# TYPE prometheus_tsdb_wal_truncations_failed_total counter
prometheus_tsdb_wal_truncations_failed_total 0
# HELP prometheus_tsdb_wal_truncations_total Total number of write log truncations attempted.
# TYPE prometheus_tsdb_wal_truncations_total counter
prometheus_tsdb_wal_truncations_total 32
# HELP prometheus_tsdb_wal_writes_failed_total Total number of write log writes that failed.
# TYPE prometheus_tsdb_wal_writes_failed_total counter
prometheus_tsdb_wal_writes_failed_total 0
# HELP prometheus_web_federation_errors_total Total number of errors that occurred while sending federation responses.
# TYPE prometheus_web_federation_errors_total counter
prometheus_web_federation_errors_total 0
# HELP prometheus_web_federation_warnings_total Total number of warnings that occurred while sending federation responses.
# TYPE prometheus_web_federation_warnings_total counter
prometheus_web_federation_warnings_total 0
# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.
# TYPE promhttp_metric_handler_requests_in_flight gauge
promhttp_metric_handler_requests_in_flight 1
# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.
# TYPE promhttp_metric_handler_requests_total counter
promhttp_metric_handler_requests_total{code="200"} 33166
promhttp_metric_handler_requests_total{code="500"} 0
promhttp_metric_handler_requests_total{code="503"} 0
